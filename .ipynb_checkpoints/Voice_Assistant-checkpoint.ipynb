{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr # recognise speech\n",
    "import playsound # to play an audio file\n",
    "from gtts import gTTS # google text to speech\n",
    "import random\n",
    "from time import ctime # get time details\n",
    "import webbrowser # open browser\n",
    "import ssl\n",
    "import certifi\n",
    "import time\n",
    "import os # to remove created audio files\n",
    "from PIL import Image\n",
    "import subprocess\n",
    "import pyautogui #screenshot\n",
    "import pyttsx3\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watermark          2.0.2\n",
      "pyautogui          0.9.50\n",
      "bs4                4.9.1\n",
      "certifi            2020.06.20\n",
      "speech_recognition 3.8.1\n",
      "PIL.Image          7.1.2\n",
      "CPython 3.7.7\n",
      "IPython 7.16.1\n"
     ]
    }
   ],
   "source": [
    "# Package versions\n",
    "%load_ext watermark\n",
    "%watermark -v -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Person Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    name = ''\n",
    "    def set_name(self, name):\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_obj = Person()\n",
    "person_obj.name = 'Matheus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistant Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assistant:\n",
    "    name = ''\n",
    "    def set_name(self, name):\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_obj = Assistant()\n",
    "assistant_obj.name = 'Bot'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Terms in Voice Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_terms(terms):\n",
    "    for term in terms:\n",
    "        if term in voice_data:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bot Speak Synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses pyttsx3 for offline speech text-to-speech\n",
    "def engine_speak_text(text):\n",
    "    text = str(text)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer() # initialise a recogniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen for audio and covert it to text\n",
    "def record_audio(ask=''):\n",
    "    with sr.Microphone() as source: # microphone as source\n",
    "        if ask:\n",
    "            engine_speak(ask)\n",
    "        audio = r.listen(source, 5, 5) # listen for the audio via source\n",
    "        print('Done listening')\n",
    "        voice_data = ''\n",
    "        try:\n",
    "            voice_data = r.recognize_google(audio) # convert audio to text\n",
    "        except sr.UnknownValueError: # error: recognizer does not understand\n",
    "            engine_speak('Sorry, I could not understand that')\n",
    "        except sr.RequestError:\n",
    "            engine_speak('Sorry, the service is down') # error: recognizer is not connected\n",
    "        print('>>', voice_data.lower()) # print what the user said\n",
    "        return voice_data.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engine_speak(audio_string):\n",
    "    audio_string = str(audio_string)\n",
    "    tts = gTTS(text=audio_string, lang='en') # Text-to-Speech (voice)\n",
    "    rand = random.randint(1, 20000000)\n",
    "    audio_file = 'audio' + str(rand) + '.mp3'\n",
    "    tts.save(audio_file) # save as mp3\n",
    "    playsound.playsound(audio_file) # play the audio file\n",
    "    print(assistant_obj.name + ':', audio_string) # Print what the app said\n",
    "    os.remove(audio_file) # Remove audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(voice_data):\n",
    "    \n",
    "    # 1: Greeting\n",
    "    if check_terms(['hey', 'hi', 'hello']):\n",
    "        greetings = ['How can I help you? ' + person_obj.name]\n",
    "        greet = greetings[random.randint(0, len(greetings)-1)]\n",
    "        engine_speak(greet)\n",
    "    \n",
    "    # 2: Time\n",
    "    if check_terms(['what time is it', \"what's the time\", 'tell me the time']):\n",
    "        time = ctime().split(\" \")[3].split(':')[0:2]\n",
    "        if time[0] == '00':\n",
    "            hours = '12'\n",
    "        else:\n",
    "            hours = time[0]\n",
    "        minutes = time[1]\n",
    "        time = hours + ' hours and ' + minutes + ' minutes'\n",
    "        engine_speak(time)\n",
    "    \n",
    "    # 3: Search Google\n",
    "    if check_terms(['search for']) and 'youtube' not in voice_data:\n",
    "        search_term = voice_data.split('for')[-1]\n",
    "        url = \"https://google.com/search?q=\" + search_term\n",
    "        webbrowser.get().open(url)\n",
    "        engine_speak('Here is what I found for ' + search_term + ' on Google')\n",
    "    \n",
    "    \n",
    "    # 4: Search Youtube\n",
    "    if check_terms(['youtube']):\n",
    "        search_term = voice_data.split('for')[-1]\n",
    "        url = \"https://www.youtube.com/results?search_query=\" + search_term\n",
    "        webbrowser.get().open(url)\n",
    "        engine_speak(\"Here is what I found for \" + search_term + \" on youtube\")       \n",
    "    \n",
    "    # 5: Weather\n",
    "    if check_terms(['weather']):\n",
    "        search_term = voice_data.split('for')[-1]    \n",
    "        url = \"https://www.google.com/search?sxsrf=ACYBGNSQwMLDByBwdVFIUCbQqya-ET7AAA%3A1578847393212&ei=oUwbXtbXDN-C4-EP-5u82AE&q=weather&oq=weather&gs_l=psy-ab.3..35i39i285i70i256j0i67l4j0i131i67j0i131j0i67l2j0.1630.4591..5475...1.2..2.322.1659.9j5j0j1......0....1..gws-wiz.....10..0i71j35i39j35i362i39._5eSPD47bv8&ved=0ahUKEwiWrJvwwP7mAhVfwTgGHfsNDxsQ4dUDCAs&uact=5\"\n",
    "        webbrowser.get().open(url)\n",
    "        engine_speak(\"Here is the weather for your location\")\n",
    "\n",
    "    # 6: Rock Paper Scissors \n",
    "    if check_terms(['rock paper scissors', 'rock-paper-scissors']):\n",
    "        voice_data = record_audio('Choose among rock, paper or scissors')\n",
    "        moves = ['rock', 'paper', 'scissors']\n",
    "        \n",
    "        cmove = random.choice(moves)\n",
    "        pmove = voice_data\n",
    "        \n",
    "        engine_speak(assistant_obj.name + ' chose ' + cmove)\n",
    "        engine_speak('You chose ' + pmove)\n",
    " \n",
    "        if pmove==cmove:\n",
    "            engine_speak(\"the match is draw\")\n",
    "        elif pmove== \"rock\" and cmove== \"scissors\":\n",
    "            engine_speak(\"Player wins\")\n",
    "        elif pmove== \"rock\" and cmove== \"paper\":\n",
    "            engine_speak(\"Computer wins\")\n",
    "        elif pmove== \"paper\" and cmove== \"rock\":\n",
    "            engine_speak(\"Player wins\")\n",
    "        elif pmove== \"paper\" and cmove== \"scissors\":\n",
    "            engine_speak(\"Computer wins\")\n",
    "        elif pmove== \"scissors\" and cmove== \"paper\":\n",
    "            engine_speak(\"Player wins\")\n",
    "        elif pmove== \"scissors\" and cmove== \"rock\":\n",
    "            engine_speak(\"Computer wins\")\n",
    "        \n",
    "    # 7: Coin flip\n",
    "    if check_terms(['toss', 'flip', 'coin']):\n",
    "        moves = ['heads', 'tails']\n",
    "        cmove = random.choice(moves)\n",
    "        engine_speak('The coin landed ' + cmove)\n",
    "    \n",
    "    # 8: Screenshot\n",
    "    if check_terms([\"capture\", \"my screen\", \"screenshot\"]):\n",
    "        myScreenshot = pyautogui.screenshot()\n",
    "        myScreenshot.save('screenshot/screen.png') \n",
    "        engine_speak('I took a screenshot for you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mila: Recording\n",
      "Done listening\n",
      ">> hello\n",
      "Done\n",
      "Q: hello\n",
      "Mila: How can I help you? Matt\n",
      "Mila: Recording\n",
      "Done listening\n",
      ">> search for unicorn\n",
      "Done\n",
      "Q: search for unicorn\n",
      "Mila: Here is what I found for  unicorn on Google\n",
      "Mila: Recording\n",
      "Done listening\n",
      ">> play rock-paper-scissors\n",
      "Done\n",
      "Q: play rock-paper-scissors\n",
      "Mila: Choose among rock, paper or scissors\n",
      "Done listening\n",
      ">> rock\n",
      "Mila: Mila chose rock\n",
      "Mila: You chose rock\n",
      "Mila: the match is draw\n",
      "Mila: Recording\n",
      "Done listening\n",
      ">> screenshot\n",
      "Done\n",
      "Q: screenshot\n",
      "Mila: I took a screenshot for you\n",
      "Mila: Recording\n",
      "Done listening\n",
      ">> quit\n",
      "Done\n",
      "Q: quit\n",
      "Mila: Goodbye\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    "    voice_data = record_audio('Recording') # get the voice input\n",
    "    print('Done')\n",
    "    print('Q:', voice_data)\n",
    "    respond(voice_data)\n",
    "    \n",
    "    # Exit\n",
    "    if check_terms(['exit', 'quit', 'goodbye']):\n",
    "        engine_speak('Goodbye')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
